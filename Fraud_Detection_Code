import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

# Load the dataset
data = pd.read_csv('new_data.csv')

# Display initial information about the dataset
print(data.head())
print(data.info())
print(data.describe())

# Identify categorical, integer, and float variables
obj = (data.dtypes == 'object')
object_cols = list(obj[obj].index)
print("Categorical variables:", len(object_cols))

int_ = (data.dtypes == 'int')
num_cols = list(int_[int_].index)
print("Integer variables:", len(num_cols))

fl = (data.dtypes == 'float')
fl_cols = list(fl[fl].index)
print("Float variables:", len(fl_cols))

# Visualize the count of each type and the relationship between type and amount
plt.figure(figsize=(10, 5))
sns.countplot(x='type', data=data)
plt.show()

plt.figure(figsize=(10, 5))
sns.barplot(x='type', y='amount', data=data)
plt.show()

# Visualize the distribution of 'step'
plt.figure(figsize=(15, 6))
sns.distplot(data['step'], bins=50)
plt.show()

# Visualize the correlation heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(data.corr(), cmap='BrBG', fmt='.2f', linewidths=2, annot=True)
plt.show()

# One-hot encoding for the 'type' column
type_new = pd.get_dummies(data['type'], drop_first=True)
data_new = pd.concat([data, type_new], axis=1)

# Display the first few rows of the new dataset
print(data_new.head())

# Define features and target variable
X = data_new.drop(['isFraud', 'type', 'nameOrig', 'nameDest'], axis=1)
y = data_new['isFraud']
print(X.shape, y.shape)

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Import machine learning models and evaluation metrics
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score as ras
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

# Define and train the models
models = [LogisticRegression(), XGBClassifier(), SVC(kernel='rbf', probability=True), RandomForestClassifier(n_estimators=7, criterion='entropy', random_state=7)]

for model in models:
    model.fit(X_train, y_train)
    print(f'{model} : ')
    
    train_preds = model.predict_proba(X_train)[:, 1]
    print('Training Accuracy : ', ras(y_train, train_preds))
    
    y_preds = model.predict_proba(X_test)[:, 1]
    print('Validation Accuracy : ', ras(y_test, y_preds))
    print()

# Plot confusion matrix for the best-performing model (XGBClassifier in this case)
from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(models[1], X_test, y_test)
plt.show()
